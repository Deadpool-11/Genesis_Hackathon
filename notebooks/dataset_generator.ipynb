{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "WZ4ceeE5Tc9W",
        "outputId": "83fa50d5-81be-4169-f5dc-ea81139a1353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating new realistic router logs...\n",
            "Generating daily application, user, and event data...\n",
            "Merging all datasets...\n",
            "\n",
            "Successfully generated the corrected dataset 'new_realistic_dataset_v2.csv'!\n",
            "Here's a preview including the previously missed columns:\n",
            "            Timestamp Device Name  total_avg_app_traffic  \\\n",
            "0 2025-06-01 00:00:00    Router_A                 556.42   \n",
            "1 2025-06-01 00:00:00    Router_B                 556.42   \n",
            "2 2025-06-01 00:00:00    Router_C                 556.42   \n",
            "3 2025-06-01 01:00:00    Router_A                 556.42   \n",
            "4 2025-06-01 01:00:00    Router_B                 556.42   \n",
            "5 2025-06-01 01:00:00    Router_C                 556.42   \n",
            "6 2025-06-01 02:00:00    Router_A                 556.42   \n",
            "7 2025-06-01 02:00:00    Router_B                 556.42   \n",
            "8 2025-06-01 02:00:00    Router_C                 556.42   \n",
            "9 2025-06-01 03:00:00    Router_A                 556.42   \n",
            "\n",
            "   total_peak_user_usage  New_Flag  \n",
            "0                 138.86         0  \n",
            "1                 138.86         0  \n",
            "2                 138.86         0  \n",
            "3                 138.86         0  \n",
            "4                 138.86         0  \n",
            "5                 138.86         0  \n",
            "6                 138.86         0  \n",
            "7                 138.86         0  \n",
            "8                 138.86         0  \n",
            "9                 138.86         0  \n",
            "\n",
            "Starting download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f50321a0-9b88-4d9f-b1fd-605542425f87\", \"new_realistic_dataset_v2.csv\", 119082)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- 1. Define Simulation Parameters ---\n",
        "start_date = datetime(2025, 6, 1)\n",
        "n_days = 15\n",
        "routers = ['Router_A', 'Router_B', 'Router_C']\n",
        "applications = ['Email', 'Video Streaming', 'File Transfer', 'Web Browsing', 'VoIP']\n",
        "users = ['User1', 'User2', 'User3', 'User4']\n",
        "\n",
        "# --- 2. Generate Base Hourly Router Logs ---\n",
        "print(\"Generating new realistic router logs...\")\n",
        "time_index = pd.to_datetime([start_date + timedelta(hours=i) for i in range(n_days * 24)])\n",
        "new_log_data = []\n",
        "\n",
        "for router in routers:\n",
        "    for ts in time_index:\n",
        "        hour = ts.hour\n",
        "        day_of_week = ts.dayofweek\n",
        "        is_peak_hours = 9 <= hour < 17 and day_of_week < 5\n",
        "        is_evening_hours = 18 <= hour < 23\n",
        "\n",
        "        base_traffic = np.random.uniform(10, 30)\n",
        "        if is_peak_hours:\n",
        "            base_traffic *= np.random.uniform(2.5, 4.0)\n",
        "        elif is_evening_hours:\n",
        "            base_traffic *= np.random.uniform(1.5, 2.5)\n",
        "\n",
        "        traffic_volume = base_traffic + np.random.normal(0, 5)\n",
        "        latency = 15 + (traffic_volume / 10) + np.random.normal(0, 5)\n",
        "        if is_peak_hours:\n",
        "            latency += np.random.uniform(5, 15)\n",
        "\n",
        "        bandwidth_used = traffic_volume * np.random.uniform(0.95, 1.1)\n",
        "\n",
        "        new_log_data.append({\n",
        "            'Timestamp': ts, 'Device Name': router,\n",
        "            'Traffic Volume (MB/s)': round(max(5, traffic_volume), 2),\n",
        "            'Latency (ms)': round(max(10, latency), 2),\n",
        "            'Bandwidth Allocated (MB/s)': 100,\n",
        "            'Bandwidth Used (MB/s)': round(max(5, bandwidth_used), 2)\n",
        "        })\n",
        "\n",
        "new_routers_df = pd.DataFrame(new_log_data)\n",
        "new_routers_df['Date'] = pd.to_datetime(new_routers_df['Timestamp'].dt.date)\n",
        "\n",
        "# --- 3. Generate Daily Summary Data (Corrected) ---\n",
        "print(\"Generating daily application, user, and event data...\")\n",
        "date_range = pd.to_datetime([start_date + timedelta(days=i) for i in range(n_days)])\n",
        "\n",
        "# App Usage (Corrected)\n",
        "app_data = []\n",
        "for date in date_range:\n",
        "    for app in applications:\n",
        "        avg_traffic = np.random.uniform(20, 150)\n",
        "        peak_traffic = avg_traffic * np.random.uniform(1.5, 4.0)\n",
        "        app_data.append({'Date': date, 'Application': app,\n",
        "                         'Average_Traffic_MB': round(avg_traffic, 2),\n",
        "                         'Peak_Traffic_MB': round(peak_traffic, 2)})\n",
        "daily_app_summary = pd.DataFrame(app_data).groupby('Date').agg(\n",
        "    total_avg_app_traffic=('Average_Traffic_MB', 'sum'),\n",
        "    total_peak_app_traffic=('Peak_Traffic_MB', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# User Activity (Corrected)\n",
        "user_data = []\n",
        "for date in date_range:\n",
        "    for user in users:\n",
        "        login_count = np.random.randint(0, 6)\n",
        "        peak_usage = np.random.uniform(5, 50) if login_count > 0 else 0\n",
        "        user_data.append({'Date': date, 'User': user,\n",
        "                           'Login_Count': login_count,\n",
        "                           'Peak_Usage_MB': round(peak_usage, 2)})\n",
        "daily_user_summary = pd.DataFrame(user_data).groupby('Date').agg(\n",
        "    total_logins=('Login_Count', 'sum'),\n",
        "    total_peak_user_usage=('Peak_Usage_MB', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Config History & External Factors\n",
        "config_data = [{'Date': start_date + timedelta(days=3), 'Device Name': 'Router_B', 'Num_Config_Changes': 1},\n",
        "               {'Date': start_date + timedelta(days=8), 'Device Name': 'Router_A', 'Num_Config_Changes': 1}]\n",
        "daily_config_summary = pd.DataFrame(config_data)\n",
        "daily_config_summary['Date'] = pd.to_datetime(daily_config_summary['Date'])\n",
        "\n",
        "external_data = [{'Date': start_date + timedelta(days=5), 'Event': 'External Outage', 'Impact': 'High'},\n",
        "                 {'Date': start_date + timedelta(days=10), 'Event': 'Scheduled Maintenance', 'Impact': 'Medium'}]\n",
        "external_factors_df = pd.DataFrame(external_data)\n",
        "external_factors_df['Date'] = pd.to_datetime(external_factors_df['Date'])\n",
        "\n",
        "# --- 4. Merge All Data and Create Target Flag ---\n",
        "print(\"Merging all datasets...\")\n",
        "merged_df = pd.merge(new_routers_df, daily_app_summary, on='Date', how='left')\n",
        "merged_df = pd.merge(merged_df, daily_user_summary, on='Date', how='left')\n",
        "merged_df = pd.merge(merged_df, external_factors_df, on='Date', how='left')\n",
        "merged_df = pd.merge(merged_df, daily_config_summary, on=['Date', 'Device Name'], how='left')\n",
        "merged_df.fillna({'Event': 'None', 'Impact': 'None', 'Num_Config_Changes': 0}, inplace=True)\n",
        "\n",
        "merged_df.loc[merged_df['Event'] == 'External Outage', 'Latency (ms)'] *= 2.5\n",
        "merged_df.loc[merged_df['Event'] == 'Scheduled Maintenance', 'Traffic Volume (MB/s)'] *= 0.1\n",
        "\n",
        "def create_new_flag(row):\n",
        "    utilization = row['Bandwidth Used (MB/s)'] / row['Bandwidth Allocated (MB/s)']\n",
        "    if utilization > 0.85 or (utilization > 0.7 and row['Latency (ms)'] > 60) or row['Event'] == 'External Outage':\n",
        "        return 1\n",
        "    return 0\n",
        "merged_df['New_Flag'] = merged_df.apply(create_new_flag, axis=1)\n",
        "\n",
        "# --- 5. Final Sorting and Saving ---\n",
        "final_df = merged_df.sort_values(by=['Timestamp', 'Device Name']).reset_index(drop=True)\n",
        "file_name = 'new_realistic_dataset_v2.csv'\n",
        "final_df.to_csv(file_name, index=False)\n",
        "\n",
        "print(f\"\\nSuccessfully generated the corrected dataset '{file_name}'!\")\n",
        "print(\"Here's a preview including the previously missed columns:\")\n",
        "print(final_df[['Timestamp', 'Device Name', 'total_avg_app_traffic', 'total_peak_user_usage', 'New_Flag']].head(10))\n",
        "\n",
        "print(\"\\nStarting download...\")\n",
        "files.download(file_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3VaVeA4rvXVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lOPSZatrvXBj"
      }
    }
  ]
}